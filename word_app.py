import streamlit as st
import pandas as pd
from openai import OpenAI
import os
from pathlib import Path
import difflib
from html import escape
from docx import Document
from io import BytesIO
import re
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
import openai
from docx.shared import Inches
import json
from typing import List, Dict
import hashlib
from datetime import datetime
from openai import AsyncOpenAI
import asyncio
import tempfile
import io

def word_app():
    # Titel der App
    st.title("BonsAI Word Dokument Sprachpr√ºfung und Korrektur")

    # --- Constants and Configurations ---

    SUPPORTED_EXTENSIONS = ('.docx',)

    # Model options for the dropdown
    MODEL_OPTIONS = {
        "GPT-4.1-mini": "gpt-4.1-mini",
        "GPT-4o": "gpt-4o"
    }

    # Language options for the dropdown
    LANGUAGE_OPTIONS = {
        "Deutsch": "de",
        "Spanisch": "es",
        "Franz√∂sisch": "fr", 
        "Englisch": "en",
        "Italienisch": "it",
        "Portugiesisch": "pt",
        "Chinesisch (Vereinfacht)": "zh-CN",
        "Chinesisch (Traditionell)": "zh-TW",
        "Japanisch": "ja",
        "Koreanisch": "ko",
        "Russisch": "ru",
        "Arabisch": "ar",
        "Hindi": "hi",
        "Niederl√§ndisch": "nl",
        "Schwedisch": "sv",
        "Norwegisch": "no",
        "D√§nisch": "da",
        "Finnisch": "fi",
        "Polnisch": "pl",
        "Tschechisch": "cs",
        "Ungarisch": "hu",
        "Rum√§nisch": "ro",
        "Bulgarisch": "bg",
        "Kroatisch": "hr",
        "Serbisch": "sr",
        "Slowakisch": "sk",
        "Slowenisch": "sl",
        "Estnisch": "et",
        "Lettisch": "lv",
        "Litauisch": "lt",
        "Griechisch": "el",
        "T√ºrkisch": "tr",
        "Hebr√§isch": "he",
        "Thai": "th",
        "Vietnamesisch": "vi",
        "Indonesisch": "id",
        "Malaiisch": "ms",
        "Filipino": "fil",
        "Ukrainisch": "uk"
    }

    # Default system prompt
    DEFAULT_SYSTEM_PROMPT = """Du bist ein hilfreicher Assistent, der Texte in {target_language} √ºbersetzt.
Behalte die urspr√ºngliche Bedeutung so genau wie m√∂glich bei.
Passe den Ton der √úbersetzung so an, dass er f√ºr professionelle Dokumente in der Zielsprache ({target_language}) angemessen ist.
Der √ºbersetzte Text sollte ungef√§hr die gleiche Zeichenl√§nge wie der urspr√ºngliche Text haben (innerhalb einer 5%-Marge).
√úbersetze keine E-Mails, Telefonnummern oder andere nicht-textuelle Inhalte.
Verwende korrekte Umlaute und Sonderzeichen f√ºr die Zielsprache.
Gib die √úbersetzung als JSON-Objekt genau wie folgt zur√ºck: {{"translated": "<√ºbersetzter Text>"}}"""

    # --- Helper Functions ---

    def generate_prompt_hash(prompt: str) -> str:
        """Generates a SHA-256 hash of the prompt for use as a cache key."""
        return hashlib.sha256(prompt.encode('utf-8')).hexdigest()

    def safe_text_extraction(text: str) -> str:
        """Safely extracts and normalizes text to handle encoding issues."""
        if not text:
            return ""
        
        # Ensure proper UTF-8 encoding
        try:
            # If text is bytes, decode it
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='replace')
            
            # Normalize the text to handle any encoding issues
            text = text.encode('utf-8', errors='replace').decode('utf-8')
            
            # Clean up any problematic characters while preserving umlauts
            text = text.strip()
            
            return text
        except Exception as e:
            st.warning(f"Textverarbeitungsfehler: {e}")
            return str(text) if text else ""

    async def translate_text_with_openai(prompt: str, target_language: str, cache: Dict, model: str = "gpt-4.1-mini", system_prompt: str = None, max_retries: int = 3) -> str:
        """Translates text using the OpenAI API, with caching and retries."""
        # Ensure proper text encoding
        prompt = safe_text_extraction(prompt)
        
        # Include system prompt in hash for separate caching
        cache_key = prompt + model + (system_prompt or DEFAULT_SYSTEM_PROMPT)
        prompt_hash = generate_prompt_hash(cache_key)
        if prompt_hash in cache:
            return cache[prompt_hash]

        # Use custom system prompt or default
        if system_prompt is None:
            system_instruction = DEFAULT_SYSTEM_PROMPT.format(target_language=target_language)
        else:
            system_instruction = system_prompt.format(target_language=target_language)

        api_key = st.session_state.get("api_key")
        if not api_key:
            raise ValueError("OpenAI API-Schl√ºssel nicht gefunden. Bitte gib deinen API-Schl√ºssel ein.")

        client = AsyncOpenAI(api_key=api_key, timeout=30.0)

        for attempt in range(max_retries):
            try:
                response = await client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_instruction},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.2,
                    max_tokens=4096,
                    timeout=30,
                    response_format={"type": "json_object"}
                )
                result = response.choices[0].message.content.strip()

                for parse_attempt in range(max_retries):
                    try:
                        parsed = json.loads(result)
                        translated_text = parsed["translated"]
                        # Ensure proper encoding of the translated text
                        translated_text = safe_text_extraction(translated_text)
                        cache[prompt_hash] = translated_text
                        return translated_text
                    except (json.JSONDecodeError, KeyError) as e:
                        if parse_attempt == max_retries - 1:
                            return prompt
                    except Exception as e:
                        return prompt

            except Exception as e:
                if attempt == max_retries - 1:
                    return prompt
        return prompt

    def extract_text_from_document(document_path: str) -> List[Dict]:
        """Extracts text and context from a Word document."""
        try:
            doc = Document(document_path)
            text_data = []

            # Extract text from paragraphs
            for para_index, paragraph in enumerate(doc.paragraphs):
                if paragraph.text.strip():
                    # Safely extract and normalize text
                    clean_text = safe_text_extraction(paragraph.text)
                    if clean_text:
                        # Determine paragraph type based on style
                        para_type = "BODY"
                        if paragraph.style.name.startswith('Heading'):
                            para_type = "HEADING"
                        elif paragraph.style.name.startswith('Title'):
                            para_type = "TITLE"
                        elif paragraph.style.name.startswith('Subtitle'):
                            para_type = "SUBTITLE"

                        text_data.append({
                            "element_type": "paragraph",
                            "element_id": f"para_{para_index}",
                            "text": clean_text,
                            "style": paragraph.style.name,
                            "para_type": para_type,
                            "para_index": para_index
                        })

            # Extract text from tables
            for table_index, table in enumerate(doc.tables):
                for row_index, row in enumerate(table.rows):
                    for col_index, cell in enumerate(row.cells):
                        if cell.text.strip():
                            # Safely extract and normalize text
                            clean_text = safe_text_extraction(cell.text)
                            if clean_text:
                                text_data.append({
                                    "element_type": "table",
                                    "element_id": f"table_{table_index}_row_{row_index}_col_{col_index}",
                                    "text": clean_text,
                                    "table_index": table_index,
                                    "row_index": row_index,
                                    "col_index": col_index
                                })

            return text_data

        except Exception as e:
            st.error(f"Fehler beim Extrahieren von Text aus dem Dokument: {e}")
            return []

    async def batch_translate_texts_with_openai(text_entries: List[Dict], target_language: str, cache: Dict, model: str = "gpt-4.1-mini", system_prompt: str = None, max_retries: int = 3, batch_size: int = 10) -> None:
        """Batch translates multiple texts using the OpenAI API with structured JSON output."""
        texts_to_translate = []
        cache_key_base = model + (system_prompt or DEFAULT_SYSTEM_PROMPT)
        
        for entry in text_entries:
            # Ensure proper text encoding
            clean_text = safe_text_extraction(entry["text"])
            cache_key = clean_text + cache_key_base
            prompt_hash = generate_prompt_hash(cache_key)
            if prompt_hash not in cache:
                texts_to_translate.append((prompt_hash, clean_text))

        if not texts_to_translate:
            return

        total_batches = (len(texts_to_translate) + batch_size - 1) // batch_size
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        tasks = []
        for batch_num, i in enumerate(range(0, len(texts_to_translate), batch_size), 1):
            batch = texts_to_translate[i:i + batch_size]
            payload = {hash_: text for hash_, text in batch}

            status_text.text(f"Verarbeite Batch {batch_num}/{total_batches} ({len(batch)} Texte)")
            progress_bar.progress(batch_num / total_batches)

            # Use custom system prompt or default for batch translation
            if system_prompt is None:
                system_instruction = f"""Du bist ein hilfreicher Assistent, der mehrere Texte in {target_language} √ºbersetzt.
Behalte die urspr√ºngliche Bedeutung so genau wie m√∂glich bei.
Passe den Ton jeder √úbersetzung so an, dass er f√ºr professionelle Dokumente in der Zielsprache ({target_language}) angemessen ist.
Der √ºbersetzte Text f√ºr jede Eingabe sollte ungef√§hr die gleiche L√§nge wie der urspr√ºngliche Text haben (innerhalb einer 10%-Marge).
Verwende korrekte Umlaute und Sonderzeichen f√ºr die Zielsprache.
Gib die √úbersetzungen als JSON-Objekt genau wie folgt zur√ºck:
{{"translations": {{"<sha256 hash>": "<√ºbersetzter Text>"}} }}"""
            else:
                system_instruction = system_prompt.format(target_language=target_language) + f"""
Verwende korrekte Umlaute und Sonderzeichen f√ºr die Zielsprache.
Gib die √úbersetzungen als JSON-Objekt genau wie folgt zur√ºck:
{{"translations": {{"<sha256 hash>": "<√ºbersetzter Text>"}} }}"""

            prompt_data = {
                "texts": payload,
                "target_language": target_language,
                "instructions": "Translate each text, maintaining original meaning and formatting. Use correct umlauts and special characters."
            }

            api_key = st.session_state.get("api_key")
            if not api_key:
                raise ValueError("OpenAI API-Schl√ºssel nicht gefunden. Bitte gib deinen API-Schl√ºssel ein.")

            client = AsyncOpenAI(api_key=api_key, timeout=60.0)
            tasks.append(translate_batch(client, system_instruction, prompt_data, cache, max_retries, batch_num, total_batches, model))

        await asyncio.gather(*tasks)
        progress_bar.progress(1.0)
        status_text.text("√úbersetzung abgeschlossen!")

    async def translate_batch(client: AsyncOpenAI, system_instruction: str, prompt_data: Dict, cache: Dict, max_retries: int, batch_num: int, total_batches: int, model: str) -> None:
        """Translates a single batch (async)."""
        for attempt in range(max_retries):
            try:
                response = await client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_instruction},
                        {"role": "user", "content": json.dumps(prompt_data, ensure_ascii=False)}
                    ],
                    temperature=0.2,
                    max_tokens=4096,
                    timeout=60,
                    response_format={"type": "json_object"}
                )
                output = response.choices[0].message.content.strip()

                for parse_attempt in range(max_retries):
                    try:
                        result = json.loads(output)
                        translations = result.get("translations", {})
                        for hash_, translated_text in translations.items():
                            # Ensure proper encoding of translated text
                            clean_translated_text = safe_text_extraction(translated_text)
                            cache[hash_] = clean_translated_text
                        break
                    except (json.JSONDecodeError, KeyError) as e:
                        if parse_attempt == max_retries - 1:
                            pass
                    except Exception as e:
                        pass
                else:
                    continue
                break

            except Exception as e:
                if attempt == max_retries - 1:
                    pass

    async def translate_document(document_file, target_language: str, model: str = "gpt-4.1-mini", system_prompt: str = None) -> bytes:
        """Translates a Word document and returns the translated version as bytes."""
        
        # Create temporary files with proper encoding
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as temp_input:
            temp_input.write(document_file.read())
            temp_input_path = temp_input.name
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as temp_output:
            temp_output_path = temp_output.name

        try:
            text_data = extract_text_from_document(temp_input_path)
            if not text_data:
                st.warning("Kein Text zum √úbersetzen im Dokument gefunden.")
                return None

            # Initialize cache for this session
            cache = {}

            await batch_translate_texts_with_openai(text_data, target_language, cache, model, system_prompt)

            # Load the document
            doc = Document(temp_input_path)

            # Apply translations
            translated_text_data = []
            cache_key_base = model + (system_prompt or DEFAULT_SYSTEM_PROMPT)
            
            for text_entry in text_data:
                clean_text = safe_text_extraction(text_entry["text"])
                cache_key = clean_text + cache_key_base
                prompt_hash = generate_prompt_hash(cache_key)
                translated_text = cache.get(prompt_hash, clean_text)
                translated_text_entry = text_entry.copy()
                translated_text_entry["translated_text"] = translated_text
                translated_text_data.append(translated_text_entry)

            # Replace text in paragraphs
            for para_index, paragraph in enumerate(doc.paragraphs):
                element_id = f"para_{para_index}"
                translated_entry = next((entry for entry in translated_text_data 
                                       if entry.get("element_id") == element_id), None)
                if translated_entry:
                    try:
                        # Preserve formatting by replacing runs
                        if paragraph.runs:
                            # Clear existing text
                            for run in paragraph.runs:
                                run.text = ""
                            # Set translated text in first run
                            paragraph.runs[0].text = translated_entry["translated_text"]
                        else:
                            # If no runs, set paragraph text directly
                            paragraph.text = translated_entry["translated_text"]
                    except Exception as e:
                        continue

            # Replace text in tables
            for table_index, table in enumerate(doc.tables):
                for row_index, row in enumerate(table.rows):
                    for col_index, cell in enumerate(row.cells):
                        element_id = f"table_{table_index}_row_{row_index}_col_{col_index}"
                        translated_entry = next((entry for entry in translated_text_data 
                                               if entry.get("element_id") == element_id), None)
                        if translated_entry:
                            try:
                                # Clear and set new text for cell
                                for paragraph in cell.paragraphs:
                                    if paragraph.runs:
                                        for run in paragraph.runs:
                                            run.text = ""
                                        paragraph.runs[0].text = translated_entry["translated_text"]
                                    else:
                                        paragraph.text = translated_entry["translated_text"]
                                    break  # Only update first paragraph in cell
                            except Exception as e:
                                continue

            doc.save(temp_output_path)
            
            # Read the translated file as bytes
            with open(temp_output_path, 'rb') as f:
                translated_bytes = f.read()
            
            return translated_bytes

        except Exception as e:
            st.error(f"Fehler w√§hrend des √úbersetzungsprozesses: {e}")
            return None
        finally:
            # Clean up temporary files
            try:
                os.unlink(temp_input_path)
                os.unlink(temp_output_path)
            except:
                pass

    # Main Streamlit app content
    st.markdown("√úbersetze deine Word-Dokumente mit OpenAI's GPT-Modellen")
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("Konfiguration")
        
        # API Key input
        api_key = st.text_input(
            "OpenAI API-Schl√ºssel",
            type="password",
            help="Gib deinen OpenAI API-Schl√ºssel ein, um den √úbersetzungsservice zu nutzen"
        )
        
        if api_key:
            st.session_state["api_key"] = api_key
            st.success("‚úÖ API-Schl√ºssel gesetzt!")
        
        # Model selection
        selected_model_name = st.selectbox(
            "KI-Modell",
            options=list(MODEL_OPTIONS.keys()),
            help="W√§hle das KI-Modell f√ºr die √úbersetzung. GPT-4.1-mini ist schneller und g√ºnstiger, GPT-4o bietet h√∂chste Qualit√§t."
        )
        
        selected_model = MODEL_OPTIONS[selected_model_name]
        
        # Show model info
        if "mini" in selected_model:
            st.info("üí° GPT-4.1-mini: Schneller & 83% g√ºnstiger als GPT-4o")
        else:
            st.info("üéØ GPT-4o: H√∂chste Qualit√§t & Genauigkeit")
        
        # Language selection
        selected_language_name = st.selectbox(
            "Zielsprache",
            options=list(LANGUAGE_OPTIONS.keys()),
            help="W√§hle die Sprache aus, in die du dein Dokument √ºbersetzen m√∂chtest"
        )
        
        target_language = LANGUAGE_OPTIONS[selected_language_name]
        
        st.info(f"Ausgew√§hlt: {selected_language_name} ({target_language})")
    
    # System prompt customization (collapsed by default)
    with st.expander("‚öôÔ∏è Systemprompt anpassen (Erweitert)", expanded=False):
        st.markdown("**Hier kannst du das Systemprompt f√ºr die √úbersetzung anpassen:**")
        
        custom_system_prompt = st.text_area(
            "Systemprompt",
            value=DEFAULT_SYSTEM_PROMPT,
            height=150,
            help="Verwende {target_language} als Platzhalter f√ºr die Zielsprache. Das Prompt sollte Anweisungen f√ºr JSON-Ausgabe enthalten."
        )
        
        if st.button("üîÑ Standard wiederherstellen"):
            st.rerun()
        
        # Show preview of formatted prompt
        if target_language:
            st.markdown("**Vorschau (formatiert):**")
            preview = custom_system_prompt.format(target_language=selected_language_name)
            st.code(preview, language="text")
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("Dokument hochladen")
        
        uploaded_file = st.file_uploader(
            "Word-Datei ausw√§hlen",
            type=['docx'],
            help="Lade eine .docx-Datei zum √úbersetzen hoch"
        )
        
        if uploaded_file is not None:
            st.success(f"‚úÖ Datei hochgeladen: {uploaded_file.name}")
            
            # Display file info
            file_size = len(uploaded_file.getvalue()) / 1024 / 1024  # MB
            st.info(f"Dateigr√∂√üe: {file_size:.2f} MB")
    
    with col2:
        st.header("√úbersetzung")
        
        if uploaded_file is not None and api_key:
            if st.button("üöÄ Dokument √ºbersetzen", type="primary"):
                with st.spinner("Dokument wird √ºbersetzt..."):
                    try:
                        # Reset file pointer
                        uploaded_file.seek(0)
                        
                        # Use custom system prompt if different from default
                        system_prompt_to_use = custom_system_prompt if custom_system_prompt != DEFAULT_SYSTEM_PROMPT else None
                        
                        # Translate the document
                        translated_bytes = asyncio.run(
                            translate_document(uploaded_file, target_language, selected_model, system_prompt_to_use)
                        )
                        
                        if translated_bytes:
                            # Generate download filename
                            original_name = uploaded_file.name.replace('.docx', '')
                            model_suffix = "mini" if "mini" in selected_model else "4o"
                            download_filename = f"{original_name}_√ºbersetzt_{target_language}_{model_suffix}.docx"
                            
                            st.success("üéâ √úbersetzung abgeschlossen!")
                            
                            # Download button
                            st.download_button(
                                label="üì• √úbersetztes Dokument herunterladen",
                                data=translated_bytes,
                                file_name=download_filename,
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                        else:
                            st.error("√úbersetzung fehlgeschlagen. Bitte versuche es erneut.")
                            
                    except Exception as e:
                        st.error(f"Ein Fehler ist aufgetreten: {str(e)}")
        
        elif not api_key:
            st.warning("‚ö†Ô∏è Bitte gib deinen OpenAI API-Schl√ºssel in der Seitenleiste ein")
        elif uploaded_file is None:
            st.info("üì§ Bitte lade ein Word-Dokument hoch, um zu beginnen")
    
    # Model comparison info
    with st.expander("üîç Modell-Vergleich"):
        st.markdown("""
        | Modell | Geschwindigkeit | Kosten | Qualit√§t | Beste Verwendung |
        |--------|----------------|--------|----------|------------------|
        | **GPT-4.1-mini** | Schneller | 83% g√ºnstiger | Sehr gut | Allt√§gliche √úbersetzungen, gro√üe Mengen |
        | **GPT-4o** | Standard | Standard | H√∂chste | Wichtige Dokumente, maximale Genauigkeit |
        
        **GPT-4.1-mini Vorteile:**
        - ‚ö° Deutlich schnellere Verarbeitung
        - üí∞ Erheblich niedrigere Kosten
        - üéØ Sehr gute Qualit√§t f√ºr die meisten Anwendungsf√§lle
        - üìÑ 1 Million Token Kontext (wie GPT-4o)
        """)
    
    # Instructions
    with st.expander("üìñ Wie man diese App verwendet"):
        st.markdown("""
        1. **OpenAI API-Schl√ºssel besorgen**: Frag Tobias oder Jonathan um den API-Schl√ºssel zu erhalten
        2. **API-Schl√ºssel eingeben**: F√ºge deinen API-Schl√ºssel in der Seitenleiste ein (er wird sicher in deiner Sitzung gespeichert)
        3. **Modell ausw√§hlen**: W√§hle zwischen GPT-4.1-mini (Standard, schneller & g√ºnstiger) oder GPT-4o (h√∂chste Qualit√§t)
        4. **Sprache ausw√§hlen**: W√§hle deine Zielsprache aus dem Dropdown-Men√º
        5. **Systemprompt anpassen** (optional): Passe das √úbersetzungsverhalten im erweiterten Bereich an
        6. **Datei hochladen**: Lade dein Word (.docx) Dokument hoch
        7. **√úbersetzen**: Klicke auf den √úbersetzen-Button und warte, bis der Prozess abgeschlossen ist
        8. **Herunterladen**: Lade dein √ºbersetztes Dokument herunter
        
        **Hinweis**: Der √úbersetzungsprozess kann je nach Gr√∂√üe deines Dokuments einige Minuten dauern.
        
        **Unterst√ºtzte Elemente:**
        - Paragraphen (Text, √úberschriften, Titel)
        - Tabellen
        - Formatierung wird beibehalten
        """)
    
    # Footer
    st.markdown("---")

# Call the function when the script is run directly
if __name__ == "__main__":
    word_app()